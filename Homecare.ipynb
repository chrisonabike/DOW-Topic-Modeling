{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "#nltk.download()  # Download text data sets, including stop words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    #/////////////////////READ THE DATA//////////////////////////////////////\n",
    "    wipes = pd.read_csv(\"wipes_reviews.csv\", header=0, encoding=\"ISO-8859-1\" )\n",
    "    \n",
    "    #/////////////////////READ THE DATA//////////////////////////////////////\n",
    "    rated_reviews = pd.read_csv(\"Ratings_Only_Reviews.csv\", header=0, encoding=\"ISO-8859-1\")\n",
    "    \n",
    "    #/////////////////////LEFT JOIN DATA ON ID///////////////////////////////\n",
    "    wipes = pd.merge(wipes, rated_reviews, how='left', on='ID')\n",
    "    \n",
    "    #/////////////////////READ IN MARKET TERMS////////////////////////////////\n",
    "    market_terms = pd.read_csv(\"wipes_market_item_name_terms.csv\", header=0, encoding=\"ISO-8859-1\" )\n",
    "    \n",
    "    return (wipes, market_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(wipes):\n",
    "    # Remove the reviews for \"wipes warmers\" and \"Dispensers\" as they are not part of the analysis\n",
    "\n",
    "    #/////////////////////REMOVE THESE ITEMS/////////////////////////////////\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Warmer\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Dispenser\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Shark Navigator\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Wipes Case\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Case Kit\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Washcloth\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"popchips\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Needles\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Lunette\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Thermos\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Carriage\")].index)\n",
    "    \n",
    "    #/////////////////////REMOVE DUPLICATES///////////////////////////////////\n",
    "    wipes = wipes.drop_duplicates(subset=('Text', 'Title'), keep='last')\n",
    "    \n",
    "    #/////////////////////REMOVE UNUSED COLUMNS///////////////////////////////\n",
    "    #wipes.columns.values\n",
    "    del wipes['Unnamed: 0']\n",
    "    del wipes['Subject']\n",
    "    del wipes['Thread Title']\n",
    "    del wipes['Author Klout Score']\n",
    "    del wipes['Site Info URL']\n",
    "    del wipes['Site Info Country']\n",
    "    del wipes['LinksCount']\n",
    "    del wipes['Review Type']\n",
    "    del wipes['Search Name']\n",
    "    del wipes['Links Count']\n",
    "\n",
    "    #/////////////////////RESET INDEX/////////////////////////////////////////\n",
    "    wipes.reset_index(level=None, drop=True, inplace=True)\n",
    "    \n",
    "    #wipes.shape\n",
    "    return (wipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letters_only(text):\n",
    "    #/////////////////////REMOVE NON-ALPHA NUMERIC CHARACTERS/////////////////\n",
    "    try:\n",
    "        x = re.sub(\"[^a-zA-Z0-9]\",              # The pattern to search for\n",
    "                   \" \",                         # The pattern to replace it with\n",
    "                   text['Item Info Item'] )     # The text to search\n",
    "    except:\n",
    "        return ('byte_code_error_ignore_this_ record')\n",
    "    return (x)\n",
    "\n",
    "def make_lower(text):\n",
    "    #/////////////////////MAKE LOWER CASE/////////////////////////////////////\n",
    "    try:\n",
    "        x = text['Product']\n",
    "        x = x.lower()\n",
    "        x = x.split()                           # Split into words\n",
    "    except:\n",
    "        return (text['Text'])\n",
    "    return( \" \".join( x ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_terms(market_terms):\n",
    "    #/////////////////////GET THE TERMS ASSOCIATED WITH THE HOME MARKET////////\n",
    "    home_terms = []\n",
    "    for i in market_terms[market_terms['Market']=='Home']['Term']:\n",
    "        if i == 'car':\n",
    "            home_terms.append('car ')\n",
    "        else:\n",
    "            home_terms.append(i)\n",
    "        home_terms.extend(['all purpose', ' bath room' ,'hardwood', 'multi-surface','multi-use','multipurpose'])\n",
    "    \n",
    "    #/////////////////////CREATE A LIST OF ADDITIONAL TERMS TO EXCLUDE/////////\n",
    "    exlude_list = ['baby','denture','beauty','facial','skincare','skin care']\n",
    "    return (home_terms, exlude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_home_products(text, market_terms,exlude_list):\n",
    "    # create a list of words for the product\n",
    "    x = text['Product']\n",
    "    x = x.split()\n",
    "    \n",
    "    if len(set(x).intersection(home_terms)) > 0:\n",
    "        if len(set(x).intersection(exlude_list)) == 0:\n",
    "            return ('KEEP')\n",
    "        else:\n",
    "            return ('REMOVE')\n",
    "    else:\n",
    "        return ('REMOVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_reviews(wipes):\n",
    "    \n",
    "    # Group the reviews by 'Item Info Item' and count how many reviews there are for those products\n",
    "    reviews_grouped = pd.DataFrame(wipes[['ID','Item Info Item']].groupby(['Item Info Item']).agg(['count']))\n",
    "    # Create the Product column based on the index (which is the unique term from Item Info Item)\n",
    "    reviews_grouped['Product'] = reviews_grouped.index\n",
    "    # Reorder and rename the columns\n",
    "    cols = ['Product', 'ID']\n",
    "    reviews_grouped = reviews_grouped[cols]\n",
    "    reviews_grouped.columns = ['Product', 'Count']\n",
    "    \n",
    "    # Reset the index on the dataframe\n",
    "    reviews_grouped.reset_index(level=None, drop=True, inplace=True)\n",
    "\n",
    "    return (reviews_grouped, reviews_grouped[reviews_grouped['Count']>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def at_least_ten_reviews(text, products_to_review):\n",
    "    x = text['Item Info Item']\n",
    "    if x in products_to_review:\n",
    "        return ('Keep')\n",
    "\n",
    "def finalize_output(wipes):\n",
    "    # Delete the colums: Product, Keep, Review\n",
    "    wipes = pd.DataFrame(wipes[wipes['Review']=='Keep'])\n",
    "    del wipes['Product']\n",
    "    del wipes['Keep']\n",
    "    del wipes['Review']\n",
    "    del wipes['Rating']\n",
    "\n",
    "    #wipes['Text'] = wipes['Text'].str.replace('\\n', '')\n",
    "    wipes.reset_index(level=None, drop=True, inplace=True)\n",
    "    return (wipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_records(text, products_to_review):\n",
    "    x = text['Item Info Item']\n",
    "    if x in products_to_review:\n",
    "        return ('Keep')\n",
    "    return (' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(wipes):\n",
    "    df = pd.DataFrame()\n",
    "    for index, row in wipes.iterrows():\n",
    "        ID = row['ID']\n",
    "        REVIEW = row['Text']\n",
    "    \n",
    "        blob_review = TextBlob(REVIEW)\n",
    "        sentences = []\n",
    "        for i in blob_review.sentences:\n",
    "            #print (i)\n",
    "            sentences.append(str(i))\n",
    "    \n",
    "        intermediate_df = pd.DataFrame({'ID': ID , 'Sentence': sentences})\n",
    "        df = df.append(intermediate_df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data(wipes, reviews_grouped, more_than_ten_reviews,only_sentences):\n",
    "    wipes.to_csv('home_products.csv', index=False)\n",
    "    reviews_grouped.to_csv('count_of_products.csv', index=False)\n",
    "    more_than_ten_reviews.to_csv('products_with_more_than_ten_reviews.csv', index=False)\n",
    "    only_sentences.to_csv('only_sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data...\n",
      "Finished In:     1.298s.\n",
      "Removing dupicates...\n",
      "Finished In:     0.918s.\n",
      "Make lowercase and remove non-alphanumerics...\n",
      "Finished In:     2.132s.\n",
      "Extract only reviews in the \"home use\" market...\n",
      "Finished In:     1.269s.\n",
      "Discard products with less than 10 reviews...\n",
      "Finished In:     0.302s.\n",
      "Separate reviews by sentence...\n",
      "Finished In:     20.989s.\n",
      "Write data to csv...\n",
      "Finished In:     0.518s.\n",
      "Done in 27.428s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "t1 = time()\n",
    "print ('Reading the data...')\n",
    "wipes, market_terms = read_data()\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Removing dupicates...')\n",
    "wipes = remove_duplicates(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Make lowercase and remove non-alphanumerics...')\n",
    "wipes['Product'] = wipes.apply(lambda text: letters_only(text), axis=1)\n",
    "wipes['Product'] = wipes.apply(lambda text: make_lower(text), axis=1)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Extract only reviews in the \"home use\" market...')\n",
    "home_terms, exlude_list = make_terms(market_terms)\n",
    "wipes['Keep'] = wipes.apply(lambda text: get_home_products(text, home_terms, exlude_list), axis=1)\n",
    "# Select only the reviews that have been marked 'KEEP,' all else is discarded\n",
    "wipes = pd.DataFrame(wipes[wipes['Keep']=='KEEP'])\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Discard products with less than 10 reviews...')\n",
    "reviews_grouped, more_than_ten_reviews = group_reviews(wipes)\n",
    "products_to_review = list(more_than_ten_reviews['Product'])\n",
    "wipes['Review'] = wipes.apply(lambda text: keep_records(text, products_to_review), axis=1)\n",
    "wipes = finalize_output(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Separate reviews by sentence...')\n",
    "only_sentences = get_sentences(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Write data to csv...')\n",
    "write_data(wipes, reviews_grouped, more_than_ten_reviews,only_sentences)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "print(\"Done in %0.3fs.\" % (time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Text</th>\n",
       "      <th>Published</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Author Location</th>\n",
       "      <th>Author Sex</th>\n",
       "      <th>Author Age</th>\n",
       "      <th>URL</th>\n",
       "      <th>Site Info Name</th>\n",
       "      <th>Review Rating</th>\n",
       "      <th>Item Info Item</th>\n",
       "      <th>Search Term</th>\n",
       "      <th>Item Info Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>93804252</td>\n",
       "      <td>Smaller Containers than Expected - Read the Quantity</td>\n",
       "      <td>Lysol wipes work well, so not much more I can say about the quality. The quantity however, was much smaller than expected. 105 wipes in all 3 containers TOTAL, so each container holds 35 wipes a piece. I wish I would have read the description more carefully, as I was disappointed when I got the wipes. I would have gone to the warehouse store for a better value. These make cute teacher's gifts when you pair it with something else though, so there's that.</td>\n",
       "      <td>1/2/2014 0:00</td>\n",
       "      <td>Cindy Thomas</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>http://www.amazon.com/Lysol-Disinfecting-Wipes-Value-Blossom/product-reviews/B004EK0RJG/ref=sr_1_84_cm_cr_acr_img?ie=UTF8&amp;showViewpoints=1&amp;sortBy=bySubmissionDateDescending</td>\n",
       "      <td>amazon.com</td>\n",
       "      <td>60</td>\n",
       "      <td>Lysol Disinfecting Wipes Value Pack, Lemon and Lime Blossom, 105 Count</td>\n",
       "      <td>wipes</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                                                 Title  \\\n",
       "0  93804252  Smaller Containers than Expected - Read the Quantity   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                        Text  \\\n",
       "0  Lysol wipes work well, so not much more I can say about the quality. The quantity however, was much smaller than expected. 105 wipes in all 3 containers TOTAL, so each container holds 35 wipes a piece. I wish I would have read the description more carefully, as I was disappointed when I got the wipes. I would have gone to the warehouse store for a better value. These make cute teacher's gifts when you pair it with something else though, so there's that.   \n",
       "\n",
       "       Published   Author Name Author Location Author Sex Author Age  \\\n",
       "0  1/2/2014 0:00  Cindy Thomas             NaN        NaN        NaN   \n",
       "\n",
       "                                                                                                                                                                            URL  \\\n",
       "0  http://www.amazon.com/Lysol-Disinfecting-Wipes-Value-Blossom/product-reviews/B004EK0RJG/ref=sr_1_84_cm_cr_acr_img?ie=UTF8&showViewpoints=1&sortBy=bySubmissionDateDescending   \n",
       "\n",
       "  Site Info Name  Review Rating  \\\n",
       "0     amazon.com             60   \n",
       "\n",
       "                                                           Item Info Item  \\\n",
       "0  Lysol Disinfecting Wipes Value Pack, Lemon and Lime Blossom, 105 Count   \n",
       "\n",
       "  Search Term Item Info Category  \n",
       "0       wipes                NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.reset_option('max_colwidth')\n",
    "#pd.reset_option('^display.', silent=True)\n",
    "#pd.set_option('display.column_space',500)\n",
    "#pd.set_option('display.width',600)\n",
    "pd.set_option('max_colwidth',600)\n",
    "#pd.set_option('display.expand_frame_repr', False)\n",
    "#pd.set_option('display.height', 700)\n",
    "wipes.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(44208, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#only_sentences.head(5)\n",
    "only_sentences.shape"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
