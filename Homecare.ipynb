{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\nltk\\twitter\\__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.options.display.max_columns = 20\n",
    "\n",
    "import re\n",
    "from time import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords # Import the stop word list\n",
    "#nltk.download()  # Download text data sets, including stop words\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    wipes = pd.read_csv(\"wipes_reviews.csv\", header=0, encoding=\"ISO-8859-1\" )\n",
    "    rated_reviews = pd.read_csv(\"Ratings_Only_Reviews.csv\", header=0, encoding=\"ISO-8859-1\")\n",
    "    \n",
    "    # Left-join the data on ID\n",
    "    wipes = pd.merge(wipes, rated_reviews, how='left', on='ID')\n",
    "    \n",
    "    market_terms = pd.read_csv(\"wipes_market_item_name_terms.csv\", header=0, encoding=\"ISO-8859-1\" )\n",
    "    \n",
    "    return (wipes, market_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_duplicates(wipes):\n",
    "\n",
    "    # Remove items identified by DOW to exclude from analysis\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Warmer\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Dispenser\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Shark Navigator\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Wipes Case\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Case Kit\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Washcloth\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"popchips\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Needles\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Lunette\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Thermos\")].index)\n",
    "    wipes = wipes.drop(wipes[wipes['Item Info Item'].str.contains(\"Carriage\")].index)\n",
    "    \n",
    "    # Drop duplicates\n",
    "    wipes = wipes.drop_duplicates(subset=('Text', 'Title'), keep='last')\n",
    "    \n",
    "    # Remove unused columns\n",
    "    del wipes['Unnamed: 0']\n",
    "    del wipes['Subject']\n",
    "    del wipes['Thread Title']\n",
    "    del wipes['Author Klout Score']\n",
    "    del wipes['Site Info URL']\n",
    "    del wipes['Site Info Country']\n",
    "    del wipes['LinksCount']\n",
    "    del wipes['Review Type']\n",
    "    del wipes['Search Name']\n",
    "    del wipes['Links Count']\n",
    "\n",
    "    # Reset index\n",
    "    wipes.reset_index(level=None, drop=True, inplace=True)\n",
    "\n",
    "    return (wipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def letters_only(text):\n",
    "    # Remove non-alpha numeric characters\n",
    "    try:\n",
    "        x = re.sub(\"[^a-zA-Z0-9]\",          # Pattern to search\n",
    "                   \" \",                     # pattern to replace\n",
    "                   text['Item Info Item'] ) # Column to search\n",
    "    except:\n",
    "        return ('byte_code_error_ignore_this_ record')\n",
    "    return (x)\n",
    "\n",
    "def make_lower(text):\n",
    "    # Make lowercase\n",
    "    try:\n",
    "        x = text['Product']\n",
    "        x = x.lower()\n",
    "        x = x.split()                       # Split into words\n",
    "    except:\n",
    "        return (text['Text'])\n",
    "    return( \" \".join( x ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_terms(market_terms):\n",
    "    # Get the terms associated with the home market\n",
    "    home_terms = []\n",
    "    for i in market_terms[market_terms['Market']=='Home']['Term']:\n",
    "        if i == 'car':\n",
    "            home_terms.append('car ')\n",
    "        else:\n",
    "            home_terms.append(i)\n",
    "        home_terms.extend(['all purpose','bath room','hardwood','multi-surface','multi-use','multipurpose'])\n",
    "    \n",
    "    # Additional list of terms to exclude\n",
    "    # Identified through iterative analysis and modeling\n",
    "    exlude_list = ['baby','denture','beauty','facial','skincare','skin care']\n",
    "    return (home_terms, exlude_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_home_products(text, home_terms, exlude_list):\n",
    "    \"\"\"Returns 'keep' if a review contains home terms and no exclusion terms.\n",
    "    Otherwise, returns 'remove' \"\"\"\n",
    "    \n",
    "    # create a list of words for the product\n",
    "    x = text['Product']\n",
    "    x = x.split()\n",
    "    \n",
    "    if len(set(x).intersection(home_terms)) > 0:\n",
    "        if len(set(x).intersection(exlude_list)) == 0:\n",
    "            return ('KEEP')\n",
    "        else:\n",
    "            return ('REMOVE')\n",
    "    else:\n",
    "        return ('REMOVE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def group_reviews(wipes):\n",
    "    \n",
    "    # Group the reviews by 'Item Info Item' and count how many reviews there are for those products\n",
    "    reviews_grouped = pd.DataFrame(wipes[['ID','Item Info Item']].groupby(['Item Info Item']).agg(['count']))\n",
    "    # Create the Product column based on the index (which is the unique term from Item Info Item)\n",
    "    reviews_grouped['Product'] = reviews_grouped.index\n",
    "    # Reorder and rename the columns\n",
    "    cols = ['Product', 'ID']\n",
    "    reviews_grouped = reviews_grouped[cols]\n",
    "    reviews_grouped.columns = ['Product', 'Count']\n",
    "    \n",
    "    # Reset the index on the dataframe\n",
    "    reviews_grouped.reset_index(level=None, drop=True, inplace=True)\n",
    "\n",
    "    return (reviews_grouped, reviews_grouped[reviews_grouped['Count']>10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def at_least_ten_reviews(text, products_to_review):\n",
    "    x = text['Item Info Item']\n",
    "    if x in products_to_review:\n",
    "        return ('Keep')\n",
    "\n",
    "def finalize_output(wipes):\n",
    "    # Delete the colums: Product, Keep, Review\n",
    "    wipes = pd.DataFrame(wipes[wipes['Review']=='Keep'])\n",
    "    del wipes['Product']\n",
    "    del wipes['Keep']\n",
    "    del wipes['Review']\n",
    "    del wipes['Rating']\n",
    "\n",
    "    #wipes['Text'] = wipes['Text'].str.replace('\\n', '')\n",
    "    wipes.reset_index(level=None, drop=True, inplace=True)\n",
    "    return (wipes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def keep_records(text, products_to_review):\n",
    "    x = text['Item Info Item']\n",
    "    if x in products_to_review:\n",
    "        return ('Keep')\n",
    "    return (' ')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sentences(wipes):\n",
    "    df = pd.DataFrame()\n",
    "    for index, row in wipes.iterrows():\n",
    "        ID = row['ID']\n",
    "        REVIEW = row['Text']\n",
    "    \n",
    "        blob_review = TextBlob(REVIEW)\n",
    "        sentences = []\n",
    "        for i in blob_review.sentences:\n",
    "            #print (i)\n",
    "            sentences.append(str(i))\n",
    "    \n",
    "        intermediate_df = pd.DataFrame({'ID': ID , 'Sentence': sentences})\n",
    "        df = df.append(intermediate_df)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_data(wipes, reviews_grouped, more_than_ten_reviews,only_sentences):\n",
    "    wipes.to_csv('home_products.csv', index=False)\n",
    "    reviews_grouped.to_csv('count_of_products.csv', index=False)\n",
    "    more_than_ten_reviews.to_csv('products_with_more_than_ten_reviews.csv', index=False)\n",
    "    only_sentences.to_csv('only_sentences.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading the data...\n",
      "Finished In:     1.298s.\n",
      "Removing dupicates...\n",
      "Finished In:     0.918s.\n",
      "Make lowercase and remove non-alphanumerics...\n",
      "Finished In:     2.132s.\n",
      "Extract only reviews in the \"home use\" market...\n",
      "Finished In:     1.269s.\n",
      "Discard products with less than 10 reviews...\n",
      "Finished In:     0.302s.\n",
      "Separate reviews by sentence...\n",
      "Finished In:     20.989s.\n",
      "Write data to csv...\n",
      "Finished In:     0.518s.\n",
      "Done in 27.428s.\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t0 = time()\n",
    "t1 = time()\n",
    "print ('Reading the data...')\n",
    "wipes, market_terms = read_data()\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Removing dupicates...')\n",
    "wipes = remove_duplicates(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Make lowercase and remove non-alphanumerics...')\n",
    "wipes['Product'] = wipes.apply(lambda text: letters_only(text), axis=1)\n",
    "wipes['Product'] = wipes.apply(lambda text: make_lower(text), axis=1)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Extract only reviews in the \"home use\" market...')\n",
    "home_terms, exlude_list = make_terms(market_terms)\n",
    "wipes['Keep'] = wipes.apply(lambda text: get_home_products(text, home_terms, exlude_list), axis=1)\n",
    "# Select only the reviews that have been marked 'KEEP,' all else is discarded\n",
    "wipes = pd.DataFrame(wipes[wipes['Keep']=='KEEP'])\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Discard products with less than 10 reviews...')\n",
    "reviews_grouped, more_than_ten_reviews = group_reviews(wipes)\n",
    "products_to_review = list(more_than_ten_reviews['Product'])\n",
    "wipes['Review'] = wipes.apply(lambda text: keep_records(text, products_to_review), axis=1)\n",
    "wipes = finalize_output(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Separate reviews by sentence...')\n",
    "only_sentences = get_sentences(wipes)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "\n",
    "t1 = time()\n",
    "print ('Write data to csv...')\n",
    "write_data(wipes, reviews_grouped, more_than_ten_reviews,only_sentences)\n",
    "print(\"Finished In:     %0.3fs.\" % (time()-t1))\n",
    "print(\"Done in %0.3fs.\" % (time() - t0))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
